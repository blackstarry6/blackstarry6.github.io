<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>基于鱼书（第一册）的知识整理（1）</title>
    <link href="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/"/>
    <url>/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p>​对于复杂的函数，感知机也隐含着能够表示它的可能性。即便是计算机进行的复杂处理，感知机（理论上）也可以将其表示出来。但坏消息是，设定权重的工作，即确定合适的、能符合预期的输入与输出的权重，现在还是由人工进行的。</p><p>​神经网络的出现就是为了解决刚才的坏消息。具体地讲，神经网络的一个重要性质是它可以自动地从数据中学习到合适的权重参数。</p><h2 id="简单例子"><a href="#简单例子" class="headerlink" title="简单例子"></a>简单例子</h2><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%AE%80%E5%8D%95%E4%BE%8B%E5%AD%90.png"></p><p>​中间层有时也称为隐藏层。“隐藏”一词的意思是，隐藏层的神经元（和输入层、输出层不同）肉眼看不见。</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>​如“激活”一词所示，激活函数的作用在于决定如何来激活输入信号的总和。</p><p>​“朴素感知机”是指单层网络，指的是激活函数使用了阶跃函数的模型。“多层感知机”是指神经网络，即使用sigmoid函数等平滑的激活函数的多层网络。</p><h3 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h3><p>$$<br>\sigma(x) &#x3D; \frac{1}{1 + e^{-x}}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pylab <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x))<br><br>x = np.arange(-<span class="hljs-number">5.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">0.1</span>)<br>y = sigmoid(x)<br>plt.plot(x, y)<br>plt.ylim(-<span class="hljs-number">0.1</span>, <span class="hljs-number">1.1</span>) <span class="hljs-comment"># 指定y轴的范围</span><br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/sigmoid%E5%87%BD%E6%95%B0%E7%9A%84%E5%9B%BE%E5%BD%A2.png"></p><p>​感知机中神经元之间流动的是0或1的二元信号，而神经网络中流动的是连续的实数值信号。</p><p>​神经网络的激活函数必须使用非线性函数。换句话说，激活函数不能使用线性函数。因为线性函数的问题在于，不管如何加深层数，总是存在与之等效的“无隐藏层的神经网络”。因此，为了发挥叠加层所带来的优势，激活函数必须使用非线性函数。</p><h3 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h3><p>$$<br>\text{ReLU}(x) &#x3D; \max(0, x)<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pylab <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> np.maximum(<span class="hljs-number">0</span>, x)<br><br>x = np.arange(-<span class="hljs-number">5.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">0.1</span>)<br>y = sigmoid(x)<br>plt.plot(x, y)<br>plt.ylim(-<span class="hljs-number">1</span>, <span class="hljs-number">5</span>) <span class="hljs-comment"># 指定y轴的范围</span><br>plt.show()<br></code></pre></td></tr></table></figure><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/ReLU%E5%87%BD%E6%95%B0%E7%9A%84%E5%9B%BE%E5%BD%A2.png"></p><h2 id="3层神经网络的实现"><a href="#3层神经网络的实现" class="headerlink" title="3层神经网络的实现"></a>3层神经网络的实现</h2><h3 id="矩阵的运算"><a href="#矩阵的运算" class="headerlink" title="矩阵的运算"></a>矩阵的运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#矩阵的点积/内积</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>np.dot(A,B)<br></code></pre></td></tr></table></figure><p>​巧妙地使用NumPy数组，可以用很少的代码完成神经网络的前向处理。</p><h3 id="符号确认"><a href="#符号确认" class="headerlink" title="符号确认"></a>符号确认</h3><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/%E6%9D%83%E9%87%8D%E7%9A%84%E7%AC%A6%E5%8F%B7.png"></p><h3 id="各层间信号传递的实现"><a href="#各层间信号传递的实现" class="headerlink" title="各层间信号传递的实现"></a>各层间信号传递的实现</h3><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/%E4%BB%8E%E8%BE%93%E5%85%A5%E5%B1%82%E5%88%B0%E7%AC%AC1%E5%B1%82%E7%9A%84%E4%BF%A1%E5%8F%B7%E4%BC%A0%E9%80%92.png"></p><p>​上图增加了表示偏置的神经元“1”。请注意，偏置的右下角的索引号只有一个。这是因为前一层的偏置神经元（神经元“1”）只有一个。</p><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/%E4%BB%8E%E8%BE%93%E5%85%A5%E5%B1%82%E5%88%B0%E7%AC%AC1%E5%B1%82%E7%9A%84%E4%BF%A1%E5%8F%B7%E4%BC%A0%E9%80%921.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">X = np.array([<span class="hljs-number">1.0</span>, <span class="hljs-number">0.5</span>])<br>W1 = np.array([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>], [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.6</span>]])<br>B1 = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>])<br><br><span class="hljs-built_in">print</span>(W1.shape) <span class="hljs-comment"># (2, 3)</span><br><span class="hljs-built_in">print</span>(X.shape) <span class="hljs-comment"># (2,)</span><br><span class="hljs-built_in">print</span>(B1.shape) <span class="hljs-comment"># (3,)</span><br><br>A1 = np.dot(X, W1) + B1<br></code></pre></td></tr></table></figure><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/%E7%AC%AC1%E5%B1%82%E4%B8%AD%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9A%84%E8%AE%A1%E7%AE%97.png"></p><p>​隐藏层的加权和（加权信号和偏置的总和）用a表示，被激活函数转换后的信号用z表示。此外，图中h()表示激活函数，这里我们使用的是sigmoid函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">Z1 = sigmoid(A1)<br><br><span class="hljs-built_in">print</span>(A1) <span class="hljs-comment"># [0.3, 0.7, 1.1]</span><br><span class="hljs-built_in">print</span>(Z1) <span class="hljs-comment"># [0.57444252, 0.66818777, 0.75026011]</span><br></code></pre></td></tr></table></figure><p>​第1层到第2层的信号传递如下：</p><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/%E7%AC%AC1%E5%B1%82%E5%88%B0%E7%AC%AC2%E5%B1%82%E7%9A%84%E4%BF%A1%E5%8F%B7%E4%BC%A0%E9%80%92.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">W2 = np.array([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.4</span>], [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.5</span>], [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>]])<br>B2 = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>])<br><br><span class="hljs-built_in">print</span>(Z1.shape) <span class="hljs-comment"># (3,)</span><br><span class="hljs-built_in">print</span>(W2.shape) <span class="hljs-comment"># (3, 2)</span><br><span class="hljs-built_in">print</span>(B2.shape) <span class="hljs-comment"># (2,)</span><br><br>A2 = np.dot(Z1, W2) + B2<br>Z2 = sigmoid(A2)<br><br></code></pre></td></tr></table></figure><p>​最后是第2层到输出层的信号传递:</p><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/%E7%AC%AC2%E5%B1%82%E5%88%B0%E8%BE%93%E5%87%BA%E5%B1%82%E7%9A%84%E4%BF%A1%E5%8F%B7%E4%BC%A0%E9%80%92.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">identity_function</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x<br><br>W3 = np.array([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>], [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.4</span>]])<br>B3 = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>])<br><br>A3 = np.dot(Z2, W3) + B3<br>Y = identity_function(A3) <span class="hljs-comment"># 或者Y = A3</span><br></code></pre></td></tr></table></figure><p>​这里我们定义了identity_function()函数（也称为“恒等函数”），并将其作为输出层的激活函数。恒等函数会将输入按原样输出，因此，这个例子中没有必要特意定义identity_function()。这里这样实现只是为了和之前的流程保持统一。另外，输出层的激活函数用σ()表示，不同于隐藏层的激活函数h()（σ读作sigma）。</p><h3 id="代码小结"><a href="#代码小结" class="headerlink" title="代码小结"></a>代码小结</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">identity_function</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_network</span>():<br>    network = &#123;&#125;<br>    network[<span class="hljs-string">&#x27;W1&#x27;</span>] = np.array([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>], [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.6</span>]])<br>    network[<span class="hljs-string">&#x27;b1&#x27;</span>] = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>])<br>    network[<span class="hljs-string">&#x27;W2&#x27;</span>] = np.array([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.4</span>], [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.5</span>], [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>]])<br>    network[<span class="hljs-string">&#x27;b2&#x27;</span>] = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>])<br>    network[<span class="hljs-string">&#x27;W3&#x27;</span>] = np.array([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>], [<span class="hljs-number">0.2</span>, <span class="hljs-number">0.4</span>]])<br>    network[<span class="hljs-string">&#x27;b3&#x27;</span>] = np.array([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>])<br><br>    <span class="hljs-keyword">return</span> network<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">network, x</span>):<br>    W1, W2, W3 = network[<span class="hljs-string">&#x27;W1&#x27;</span>], network[<span class="hljs-string">&#x27;W2&#x27;</span>], network[<span class="hljs-string">&#x27;W3&#x27;</span>]<br>    b1, b2, b3 = network[<span class="hljs-string">&#x27;b1&#x27;</span>], network[<span class="hljs-string">&#x27;b2&#x27;</span>], network[<span class="hljs-string">&#x27;b3&#x27;</span>]<br><br>    a1 = np.dot(x, W1) + b1<br>    z1 = sigmoid(a1)<br>    a2 = np.dot(z1, W2) + b2<br>    z2 = sigmoid(a2)<br>    a3 = np.dot(z2, W3) + b3<br>    y = identity_function(a3)<br><br>    <span class="hljs-keyword">return</span> y<br><br>network = init_network()<br>x = np.array([<span class="hljs-number">1.0</span>, <span class="hljs-number">0.5</span>])<br>y = forward(network, x)<br><span class="hljs-built_in">print</span>(y) <span class="hljs-comment"># [ 0.31682708 0.69627909]</span><br><br><br></code></pre></td></tr></table></figure><ul><li>init_network()函数进行权重和偏置的初始化，并将它们保存在字典变量network中。这个字典变量network中保存了每一层所需的参数（权重和偏置）。</li><li>forward()函数中封装了将输入信号转换为输出信号的处理过程。</li></ul><h2 id="输出层的设计"><a href="#输出层的设计" class="headerlink" title="输出层的设计"></a>输出层的设计</h2><p>​一般而言，回归问题用恒等函数，分类问题用softmax函数。</p><p>​机器学习的问题大致可以分为分类问题和回归问题。分类问题是数据属于哪一个类别的问题。而回归问题是根据某个输入预测一个（连续的）数值的问题。</p><h3 id="softmax函数"><a href="#softmax函数" class="headerlink" title="softmax函数"></a>softmax函数</h3><p>$$<br>\text{Softmax}(x_i) &#x3D; \frac{e^{x_i}}{\sum_{j} e^{x_j}}<br>$$</p><p>​exp(x)是表示的指数函数（e是纳皮尔常数2.7182 …）。上式表示假设输出层共有n个神经元，计算第k个神经元的输出。softmax函数的分子是输入信号的指数函数，分母是所有输入信号的指数函数的和。</p><p>​softmax函数的输出通过箭头与所有的输入信号相连。这是因为，从式子中可以看出，输出层的各个神经元都受到所有输入信号的影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">a</span>):<br>    exp_a = np.exp(a)<br>    sum_exp_a = np.<span class="hljs-built_in">sum</span>(exp_a)<br>    y = exp_a / sum_exp_a<br><br>    <span class="hljs-keyword">return</span> y<br><br></code></pre></td></tr></table></figure><h3 id="实现softmax函数时的注意事项"><a href="#实现softmax函数时的注意事项" class="headerlink" title="实现softmax函数时的注意事项"></a>实现softmax函数时的注意事项</h3><p>​softmax函数的实现中要进行指数函数的运算，但是此时指数函数的值很容易变得非常大。比如，e^10的值会超过20000，会变成一个后面有40多个0的超大值，e^100的结果会返回一个表示无穷大的inf。如果在这些超大值之间进行除法运算，结果会出现“不确定”的情况。</p><p><img src="/2025/03/08/%E5%9F%BA%E4%BA%8E%E9%B1%BC%E4%B9%A6%EF%BC%88%E7%AC%AC%E4%B8%80%E5%86%8C%EF%BC%89%E7%9A%84%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86%EF%BC%881%EF%BC%89/softmax%E5%87%BD%E6%95%B0%E7%9A%84%E6%94%B9%E8%BF%9B.png"></p><p>​式(3.11)说明，在进行softmax的指数函数的运算时，加上（或者减去）某个常数并不会改变运算的结果。这里的C’可以使用任何值，但是为了防止溢出，一般会使用输入信号中的最大值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">a</span>):<br>    c = np.<span class="hljs-built_in">max</span>(a)<br>    exp_a = np.exp(a - c) <span class="hljs-comment"># 溢出对策</span><br>    sum_exp_a = np.<span class="hljs-built_in">sum</span>(exp_a)<br>    y = exp_a / sum_exp_a<br><br>    <span class="hljs-keyword">return</span> y<br><br></code></pre></td></tr></table></figure><h3 id="softmax函数的特征"><a href="#softmax函数的特征" class="headerlink" title="softmax函数的特征"></a>softmax函数的特征</h3><p>​softmax函数的输出是0.0到1.0之间的实数。并且，softmax函数的输出值的总和是1。输出总和为1是softmax函数的一个重要性质。正因为有了这个性质，我们才可以把softmax函数的输出解释为“概率”。</p><p>​一般而言，神经网络只把输出值最大的神经元所对应的类别作为识别结果。并且，即便使用softmax函数，输出值最大的神经元的位置也不会变。因此，神经网络在进行分类时，输出层的softmax函数可以省略。</p><p>​在实际的问题中，由于指数函数的运算需要一定的计算机运算量，因此输出层的softmax函数一般会被省略。</p><p>​求解机器学习问题的步骤可以分为“学习”和“推理”两个阶段。首先，在学习阶段进行模型的学习，然后，在推理阶段，用学到的模型对未知的数据进行推理（分类）。</p><p>​如前所述，推理阶段一般会省略输出层的softmax函数。在输出层使用softmax函数是因为它和神经网络的学习有关系。</p><h3 id="输出层的神经元数量"><a href="#输出层的神经元数量" class="headerlink" title="输出层的神经元数量"></a>输出层的神经元数量</h3><p>​对于分类问题，输出层的神经元数量一般设定为类别的数量。</p><h2 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h2><p>​假设学习已经全部结束，我们使用学习到的参数，先实现神经网络的“推理处理”。这个推理处理也称为神经网络的前向传播(forward propagation)。</p><p>​和求解机器学习问题的步骤（分成学习和推理两个阶段进行）一样，使用神经网络解决问题时，也需要首先使用训练数据（学习数据）进行权重参数的学习；进行推理时，使用刚才学习到的参数，对输入数据进行分类。</p><h3 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#需要科学上网下载数据集</span><br><span class="hljs-keyword">import</span> sys, os<br>sys.path.append(os.pardir) <span class="hljs-comment"># 为了导入父目录中的文件而进行的设定</span><br><span class="hljs-keyword">from</span> dataset.mnist <span class="hljs-keyword">import</span> load_mnist<br><br><span class="hljs-comment"># 第一次调用会花费几分钟……</span><br>(x_train, t_train), (x_test, t_test) = load_mnist(flatten=<span class="hljs-literal">True</span>,<br>normalize=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 输出各个数据的形状</span><br><span class="hljs-built_in">print</span>(x_train.shape) <span class="hljs-comment"># (60000, 784)</span><br><span class="hljs-built_in">print</span>(t_train.shape) <span class="hljs-comment"># (60000,)</span><br><span class="hljs-built_in">print</span>(x_test.shape) <span class="hljs-comment"># (10000, 784)</span><br><span class="hljs-built_in">print</span>(t_test.shape) <span class="hljs-comment"># (10000,)</span><br>·<br></code></pre></td></tr></table></figure><p>​load_mnist 函数以“（训练图像,训练标签），（测试图像,测试标签）”的形式返回读入的MNIST数据。</p><p>​还可以像load_mnist(normalize&#x3D;True, flatten&#x3D;True, one_hot_label&#x3D;False)这样，设置3个参数。</p><ul><li>第1个参数normalize设置是否将输入图像正规化为0.0～1.0的值。如果将该参数设置为False，则输入图像的像素会保持原来的0～255。</li><li>第2个参数flatten设置是否展开输入图像（变成一维数组）。如果将该参数设置为False，则输入图像为1×28×28的三维数组；若设置为True，则输入图像会保存为由784个元素构成的一维数组。</li><li>第3个参数one_hot_label设置是否将标签保存为one-hot表示(one-hot representation)。one-hot表示是仅正确解标签为1，其余皆为0的数组，就像[0,0,1,0,0,0,0,0,0,0]这样。当one_hot_label为False时，只是像7、2这样简单保存正确解标签；当one_hot_label为True时，标签则保存为one-hot表示。</li></ul><p>​Python有pickle这个便利的功能。这个功能可以将程序运行中的对象保存为文件。如果加载保存过的pickle文件，可以立刻复原之前程序运行中的对象。用于读入MNIST数据集的load_mnist()函数内部也使用了pickle功能（在第2次及以后读入时）。利用pickle功能，可以高效地完成MNIST数据的准备工作。</p><p>​试着显示MNIST图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys, os<br>sys.path.append(os.pardir)<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> dataset.mnist <span class="hljs-keyword">import</span> load_mnist<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">img_show</span>(<span class="hljs-params">img</span>):<br>    pil_img = Image.fromarray(np.uint8(img))<br>    pil_img.show()<br><br>(x_train, t_train), (x_test, t_test) = load_mnist(flatten=<span class="hljs-literal">True</span>,<br>normalize=<span class="hljs-literal">False</span>)<br>img = x_train[<span class="hljs-number">0</span>]<br>label = t_train[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(label) <span class="hljs-comment"># 5</span><br><br><span class="hljs-built_in">print</span>(img.shape)          <span class="hljs-comment"># (784,)</span><br>img = img.reshape(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>) <span class="hljs-comment"># 把图像的形状变成原来的尺寸</span><br><span class="hljs-built_in">print</span>(img.shape)          <span class="hljs-comment"># (28, 28)</span><br><br>img_show(img)<br><br></code></pre></td></tr></table></figure><p>​flatten&#x3D;True时读入的图像是以一列（一维）NumPy数组的形式保存的。因此，显示图像时，需要把它变为原来的28像素×28像素的形状。可以通过reshape()方法的参数指定期望的形状，更改NumPy数组的形状。此外，还需要把保存为NumPy数组的图像数据转换为PIL用的数据对象，这个转换处理由Image.fromarray()来完成。</p><h3 id="神经网络的推理处理"><a href="#神经网络的推理处理" class="headerlink" title="神经网络的推理处理"></a>神经网络的推理处理</h3><p>​对这个MNIST数据集实现神经网络的推理处理。神经网络的输入层有784个神经元，输出层有10个神经元。输入层的784这个数字来源于图像大小的28×28 &#x3D; 784，输出层的10这个数字来源于10类别分类（数字0到9，共10类别）。此外，这个神经网络有2个隐藏层，第1个隐藏层有50个神经元，第2个隐藏层有100个神经元。这个50和100可以设置为任何值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding: utf-8</span><br><span class="hljs-keyword">import</span> sys, os<br>sys.path.append(os.pardir)  <span class="hljs-comment"># 为了导入父目录的文件而进行的设定</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">from</span> dataset.mnist <span class="hljs-keyword">import</span> load_mnist<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">if</span> x.ndim == <span class="hljs-number">2</span>:<br>        x = x.T<br>        x = x - np.<span class="hljs-built_in">max</span>(x, axis=<span class="hljs-number">0</span>)<br>        y = np.exp(x) / np.<span class="hljs-built_in">sum</span>(np.exp(x), axis=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> y.T<br><br>    x = x - np.<span class="hljs-built_in">max</span>(x) <span class="hljs-comment"># 溢出对策</span><br>    <span class="hljs-keyword">return</span> np.exp(x) / np.<span class="hljs-built_in">sum</span>(np.exp(x))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_data</span>():<br>    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=<span class="hljs-literal">True</span>, flatten=<span class="hljs-literal">True</span>, one_hot_label=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">return</span> x_test, t_test<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_network</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;sample_weight.pkl&quot;</span>, <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        network = pickle.load(f)<br>    <span class="hljs-keyword">return</span> network<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">network, x</span>):<br>    W1, W2, W3 = network[<span class="hljs-string">&#x27;W1&#x27;</span>], network[<span class="hljs-string">&#x27;W2&#x27;</span>], network[<span class="hljs-string">&#x27;W3&#x27;</span>]<br>    b1, b2, b3 = network[<span class="hljs-string">&#x27;b1&#x27;</span>], network[<span class="hljs-string">&#x27;b2&#x27;</span>], network[<span class="hljs-string">&#x27;b3&#x27;</span>]<br><br>    a1 = np.dot(x, W1) + b1<br>    z1 = sigmoid(a1)<br>    a2 = np.dot(z1, W2) + b2<br>    z2 = sigmoid(a2)<br>    a3 = np.dot(z2, W3) + b3<br>    y = softmax(a3)<br><br>    <span class="hljs-keyword">return</span> y<br><br><br>x, t = get_data()<br>network = init_network()<br>accuracy_cnt = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x)):<br>    y = predict(network, x[i])<br>    p= np.argmax(y) <span class="hljs-comment"># 获取概率最高的元素的索引</span><br>    <span class="hljs-keyword">if</span> p == t[i]:<br>        accuracy_cnt += <span class="hljs-number">1</span><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy:&quot;</span> + <span class="hljs-built_in">str</span>(<span class="hljs-built_in">float</span>(accuracy_cnt) / <span class="hljs-built_in">len</span>(x)))<br></code></pre></td></tr></table></figure><p>​init_network()会读入保存在pickle文件sample_weight.pkl中的学习到的权重参数。这个文件中以字典变量的形式保存了权重和偏置参数。</p><p>​现在，我们用这3个函数来实现神经网络的推理处理。然后，评价它的识别精度(accuracy)，即能在多大程度上正确分类。</p><p>​predict()函数以NumPy数组的形式输出各个标签对应的概率。比如输出[0.1, 0.3, 0.2, …, 0.04]的数组，该数组表示“0”的概率为0.1，“1”的概率为0.3，等等。然后，我们取出这个概率列表中的最大值的索引（第几个元素的概率最高），作为预测结果。可以用np.argmax(x)函数取出数组中的最大值的索引，np.argmax(x)将获取被赋给参数x的数组中的最大值元素的索引。最后，比较神经网络所预测的答案和正确解标签，将回答正确的概率作为识别精度。</p><p>​在这个例子中，我们把load_mnist函数的参数normalize设置成了True。将normalize设置成True后，函数内部会进行转换，将图像的各个像素值除以255，使得数据的值在0.0～1.0的范围内。像这样把数据限定到某个范围内的处理称为正规化(normalization)。此外，对神经网络的输入数据进行某种既定的转换称为预处理(pre-processing)。这里，作为对输入图像的一种预处理，我们进行了正规化。</p><h2 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h2><p>​这种打包式的输入数据称为批(batch)。</p><p>​批处理对计算机的运算大有利处，可以大幅缩短每张图像的处理时间。</p><p>​为什么批处理可以缩短处理时间呢？这是因为大多数处理数值计算的库都进行了能够高效处理大型数组运算的最优化。并且，在神经网络的运算中，当数据传送成为瓶颈时，批处理可以减轻数据总线的负荷（严格地讲，相对于数据读入，可以将更多的时间用在计算上）。也就是说，批处理一次性计算大型数组要比分开逐步计算各个小型数组速度更快。</p><p>​我们给定了参数axis&#x3D;1。这指定了在100×10的数组中，沿着第1维方向（以第1维为轴）找到值最大的元素的索引（第0维对应第1个维度）。</p><p>​使用批处理，可以实现高速且高效的运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">x, t = get_data()<br>network = init_network()<br><br>batch_size = <span class="hljs-number">100</span> <span class="hljs-comment"># 批数量</span><br>accuracy_cnt = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x), batch_size):<br>    x_batch = x[i:i+batch_size]<br>    y_batch = predict(network, x_batch)<br>    p = np.argmax(y_batch, axis=<span class="hljs-number">1</span>)<br>    accuracy_cnt += np.<span class="hljs-built_in">sum</span>(p == t[i:i+batch_size])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding: utf-8</span><br><span class="hljs-keyword">import</span> sys, os<br>sys.path.append(os.pardir)  <span class="hljs-comment"># 为了导入父目录的文件而进行的设定</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">from</span> dataset.mnist <span class="hljs-keyword">import</span> load_mnist<br><span class="hljs-keyword">from</span> functions <span class="hljs-keyword">import</span> sigmoid, softmax<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_data</span>():<br>    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=<span class="hljs-literal">True</span>, flatten=<span class="hljs-literal">True</span>, one_hot_label=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">return</span> x_test, t_test<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_network</span>():<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;sample_weight.pkl&quot;</span>, <span class="hljs-string">&#x27;rb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        network = pickle.load(f)<br>    <span class="hljs-keyword">return</span> network<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">network, x</span>):<br>    w1, w2, w3 = network[<span class="hljs-string">&#x27;W1&#x27;</span>], network[<span class="hljs-string">&#x27;W2&#x27;</span>], network[<span class="hljs-string">&#x27;W3&#x27;</span>]<br>    b1, b2, b3 = network[<span class="hljs-string">&#x27;b1&#x27;</span>], network[<span class="hljs-string">&#x27;b2&#x27;</span>], network[<span class="hljs-string">&#x27;b3&#x27;</span>]<br><br>    a1 = np.dot(x, w1) + b1<br>    z1 = sigmoid(a1)<br>    a2 = np.dot(z1, w2) + b2<br>    z2 = sigmoid(a2)<br>    a3 = np.dot(z2, w3) + b3<br>    y = softmax(a3)<br><br>    <span class="hljs-keyword">return</span> y<br><br><br>x, t = get_data()<br>network = init_network()<br><br>batch_size = <span class="hljs-number">100</span> <span class="hljs-comment"># 批数量</span><br>accuracy_cnt = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(x), batch_size):<br>    x_batch = x[i:i+batch_size]<br>    y_batch = predict(network, x_batch)<br>    p = np.argmax(y_batch, axis=<span class="hljs-number">1</span>)<br>    accuracy_cnt += np.<span class="hljs-built_in">sum</span>(p == t[i:i+batch_size])<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy:&quot;</span> + <span class="hljs-built_in">str</span>(<span class="hljs-built_in">float</span>(accuracy_cnt) / <span class="hljs-built_in">len</span>(x)))<br><br></code></pre></td></tr></table></figure><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>​神经网络和感知机在信号的按层传递这一点上是相同的，但是，向下一个神经元发送信号时，改变信号的激活函数有很大差异。神经网络中使用的是平滑变化的sigmoid函数，而感知机中使用的是信号急剧变化的阶跃函数。这个差异对于神经网络的学习非常重要。</p><ul><li>神经网络中的激活函数使用平滑变化的sigmoid函数或ReLU函数。</li><li>通过巧妙地使用NumPy多维数组，可以高效地实现神经网络。</li><li>机器学习的问题大体上可以分为回归问题和分类问题。</li><li>关于输出层的激活函数，回归问题中一般用恒等函数，分类问题中一般用softmax函数。</li><li>分类问题中，输出层的神经元的数量设置为要分类的类别数</li><li>·输入数据的集合称为批。通过以批为单位进行推理处理，能够实现高速的运算。</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI-Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Win7环境下VMareTools的安装</title>
    <link href="/2025/03/04/win7-vmare-tools/"/>
    <url>/2025/03/04/win7-vmare-tools/</url>
    
    <content type="html"><![CDATA[<h1 id="安装VMare-Tools"><a href="#安装VMare-Tools" class="headerlink" title="安装VMare Tools"></a>安装VMare Tools</h1><h2 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h2><p>1、在VMare中启动win7后，点击VMare主界面的**虚拟机(M)**选项，启动VMare Tools的安装;</p><p><img src="/2025/03/04/win7-vmare-tools/vmare_tools_dow_1.png"></p><p><img src="/2025/03/04/win7-vmare-tools/vmare_tools_dow_2.png"></p><p><img src="/2025/03/04/win7-vmare-tools/vmare_tools_dow_3.png"></p><p>2、点击允许 setup64.exe，一路下一步直到完成安装；</p><p><img src="/2025/03/04/win7-vmare-tools/vmare_tools_dow_4.png"></p><h2 id="安装失败的问题"><a href="#安装失败的问题" class="headerlink" title="安装失败的问题"></a>安装失败的问题</h2><p>​安装程序中途报错，显示无法自动安装 Virtual Machine Communication Interface Sockets (VSock) 驱动程序，必须手动安装此驱动程序。</p><p><img src="/2025/03/04/win7-vmare-tools/vmare_tools_dow_5.png"></p><p>​原因是微软更新了驱动程序的签名算法，从 2019 年初开始，逐步弃用SHA-1，改为SHA-2。可以通过安装补丁来解决这个问题。</p><p>​可以从 Microsoft Update Catalog 下载 KB4474419 和 KB4490628 这两个补丁，然后安装到 Win7 虚拟机中。在没有成功安装 VMware Tools的情况下，传文件不太方便，可以用虚拟机里浏览器访问下载页面，然后直接在虚拟机里下载安装。下载地址：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">https://www.catalog.<span class="hljs-keyword">update</span>.microsoft.<span class="hljs-keyword">com</span>/<span class="hljs-built_in">search</span>.aspx?q=kb4474419<br></code></pre></td></tr></table></figure><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim">https://www.catalog.<span class="hljs-keyword">update</span>.microsoft.<span class="hljs-keyword">com</span>/<span class="hljs-built_in">search</span>.aspx?q=<span class="hljs-number">4490628</span><br></code></pre></td></tr></table></figure><p>​安装补丁后，重启虚拟机，然后重新 VMware Tools 即可。</p><p>​</p><p>​或者使用附录的ISO文件进行补丁安装。</p><h2 id="附录文件"><a href="#附录文件" class="headerlink" title="附录文件"></a>附录文件</h2><p>1、<a href="https://dl.google.com/release2/chrome/acihtkcueyye3ymoj2afvv7ulzxa_109.0.5414.120/109.0.5414.120_chrome_installer.exe">适合win7的32位Google </a></p><p>2、<a href="ISO%E8%A1%A5%E4%B8%81.zip">下载 ISO </a></p><p>3、<a href="ISO%E8%A1%A5%E4%B8%81.z01">下载 ISO 1</a></p><p>4、<a href="ISO%E8%A1%A5%E4%B8%81.z02">下载 ISO 2</a></p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p>1、<a href="https://ihacksoft.com/archive/1397.html">完美解决：安装程序无法自动安装 Virtual Machine Communication…… - 嗨软</a></p><p>2、<a href="https://www.catalog.update.microsoft.com/search.aspx?q=kb4474419">https://www.catalog.update.microsoft.com/search.aspx?q=kb4474419</a></p><p>3、<a href="https://blog.csdn.net/Drug_/article/details/141402451">Chrome 浏览器 Windows 7 最终版下载（官方原版）_chrome win7-CSDN博客</a></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>Env_Config</category>
      
    </categories>
    
    
    <tags>
      
      <tag>VMaretools</tag>
      
      <tag>win7</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DS的基础使用</title>
    <link href="/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/"/>
    <url>/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><h2 id="AI原生应用市场"><a href="#AI原生应用市场" class="headerlink" title="AI原生应用市场"></a>AI原生应用市场</h2><ul><li>国产大模型迭代和应用加速（技术突破：强化学习和混合专家架构结合）；</li><li>端侧和边缘计算应用繁荣；</li><li>智能安全和安全智能。</li></ul><h2 id="中小型企业"><a href="#中小型企业" class="headerlink" title="中小型企业"></a>中小型企业</h2><ul><li>价格竞争；</li><li>生态选择；</li><li>场景应用。</li></ul><h2 id="政府及头部企业市场"><a href="#政府及头部企业市场" class="headerlink" title="政府及头部企业市场"></a>政府及头部企业市场</h2><ul><li>智算中心+专业智能体；</li><li>企业级安全与合规保障；</li><li>终端及边缘智能化。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>破除算力霸权；</li><li>商业模型颠覆（NaaS:模型即服务）；</li><li>技术平权。</li></ul><h1 id="基础介绍"><a href="#基础介绍" class="headerlink" title="基础介绍"></a>基础介绍</h1><h2 id="ChatGPT"><a href="#ChatGPT" class="headerlink" title="ChatGPT"></a>ChatGPT</h2><ul><li>“Chat”代表聊天；</li><li>“G”（Generative）代表生成式；</li><li>“P”（Pre-trained）代表预训练；</li><li>“T”<strong>（Transformer）代表Transformer架构</strong>。</li><li>在GPT (Generative Pre-trained Transformer)中，生成式 (generative)意味着这个模型能够生成新的文本序列。</li></ul><h2 id="影响模型的三要素"><a href="#影响模型的三要素" class="headerlink" title="影响模型的三要素"></a>影响模型的三要素</h2><ul><li>算力；</li><li>算法；</li><li>数据。</li></ul><h2 id="提示词框架：BRROKE（融合OKR）"><a href="#提示词框架：BRROKE（融合OKR）" class="headerlink" title="提示词框架：BRROKE（融合OKR）"></a>提示词框架：BRROKE（融合OKR）</h2><ol><li>背景：提供足够的背景信息，使得GPT能够理解问题的上下文；</li><li>角色：设定特定的角色，让GPT能根据该角色来生成响应；</li><li>目标：明确任务目标，让GPT清楚知道需要实现什么；</li><li>要点：定义关键的、可以衡量的结果，以便让GPT知道如何衡量目标的完成情况；</li><li>测试：1次不对，就鼓励AI分步骤，多试几次。通过调整来测试结果，并根据需要进行优化。</li></ol><h2 id="五个技巧"><a href="#五个技巧" class="headerlink" title="五个技巧"></a>五个技巧</h2><ul><li>定目标——抛弃套路，直抒胸臆，但是注意细节；<ul><li>通用公式：我要XX，要给XX用，希望达到XX效果，但是担心XX问题。</li></ul></li><li>说人话；</li><li>补数据——数据类型包括文案、示例、PDF、Excel等，用来给AI补充背景信息；</li><li>勤反问——发挥人的主动性；</li><li>善联动。</li></ul><p><img src="/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/%E5%AE%9A%E7%9B%AE%E6%A0%87%E7%9A%84%E7%BB%86%E8%8A%82.png"></p><p><img src="/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/%E8%AF%B4%E4%BA%BA%E8%AF%9D.png"></p><p><img src="/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/%E8%A1%A5%E6%95%B0%E6%8D%AE.png"></p><p><img src="/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/%E9%AB%98%E7%BA%A7%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7.png"></p><p><img src="/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/%E5%8B%A4%E5%8F%8D%E9%97%AE.png"></p><p><img src="/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/%E5%AE%9E%E6%93%8D.png"></p><p><img src="/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/%E4%B8%8EAI%E6%B2%9F%E9%80%9A.png"></p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><ul><li>秘塔AI搜索；</li><li>纳米AI搜索；</li><li>DeepSeek +阿里通义 快速生成PPT模板；</li><li>DeepSeek +即梦AI 完成AI绘画；</li><li>AI精选工具库</li></ul><p><img src="/2025/02/21/DS%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/%E4%B8%8D%E5%90%8CAI%E7%9A%84%E4%BC%98%E5%8A%BF.png"></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI-Use</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>个人博客搭建流程</title>
    <link href="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/"/>
    <url>/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="一、前期准备"><a href="#一、前期准备" class="headerlink" title="一、前期准备"></a>一、前期准备</h1><h2 id="1、github账号"><a href="#1、github账号" class="headerlink" title="1、github账号"></a>1、github账号</h2><h2 id="2、git安装"><a href="#2、git安装" class="headerlink" title="2、git安装"></a>2、git安装</h2><p>配置</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">git config <span class="hljs-attr">--global</span> user<span class="hljs-selector-class">.name</span> <span class="hljs-string">&quot;Your Name&quot;</span><br>git config <span class="hljs-attr">--global</span> user<span class="hljs-selector-class">.email</span> <span class="hljs-string">&quot;email@example.com&quot;</span><br></code></pre></td></tr></table></figure><h2 id="3、NodeJS安装和（可选）配置"><a href="#3、NodeJS安装和（可选）配置" class="headerlink" title="3、NodeJS安装和（可选）配置"></a>3、NodeJS安装和（可选）配置</h2><p>备注：以管理员身份打开cmd窗口</p><ol><li><p><a href="https://nodejs.org/zh-cn/download/">NodeJS官网下载</a>，安装路径可以选择自定义路径，如D:\myweb\NodeJs</p></li><li><p>验证NodeJS安装，即查看node和npm版本</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crmsh"><span class="hljs-keyword">node</span> <span class="hljs-title">-v</span><br>npm -v<br></code></pre></td></tr></table></figure></li><li><p>在安装目录（D:\myweb\NodeJs）下创建两个文件夹，<code>node_global</code> 存放全局包，<code>node_cache</code> 存放node缓存和log记录</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">npm root -<span class="hljs-selector-tag">g</span> <br><span class="hljs-comment">//查看当前路径</span><br></code></pre></td></tr></table></figure></li><li><p>在cmd命令行中执行如下两条命令</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">npm<span class="hljs-built_in"> config </span><span class="hljs-built_in">set</span><span class="hljs-built_in"> prefix </span><span class="hljs-string">&quot;D:\xgweb\NodeJs\node_global&quot;</span><br><br>npm<span class="hljs-built_in"> config </span><span class="hljs-built_in">set</span> cache <span class="hljs-string">&quot;D:\xgweb\NodeJs\node_cache&quot;</span><br><br></code></pre></td></tr></table></figure></li><li><p>设置电脑环境变量，右键 “我的电脑”&#x3D;》属性&#x3D;》高级系统设置&#x3D;》环境变量；进入环境变量对话框，在【系统变量】中新建环境变量 <code>NODE_PATH</code>，值为 <code>D:\xgweb\NodeJs\node_global\node_modules</code>，其中 <code>D:\xgweb\NodeJs\node_global</code> 是新创建的全局模块安装路径；修改【用户变量】中的 <code>path</code> 变量，将 <code>C:\Users\..\AppData\Roaming\npm</code> 修改为<code>D:\xgweb\NodeJs\node_global</code></p></li><li><p>重启电脑，使配置生效</p></li></ol><h1 id="二、创建仓库"><a href="#二、创建仓库" class="headerlink" title="二、创建仓库"></a>二、创建仓库</h1><ol><li><p>在<code>GitHub</code>上创建一个新的代码仓库用于保存我们的网页。</p></li><li><p>点击<code>Your repositories</code>，进入仓库页面。点击<code>New</code>按钮，进入仓库创建页面，填写仓库名，格式必须为<code>&lt;用户名&gt;.github.io</code>，然后点击<code>Create repository</code>。</p></li><li><p>点击<code>creating a new file</code>创建一个新文件，作为我们网站的主页。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-keyword">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">html</span> <span class="hljs-attr">lang</span>=<span class="hljs-string">&quot;en&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">&quot;UTF-8&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>111<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">h1</span>&gt;</span>111的个人主页<span class="hljs-tag">&lt;/<span class="hljs-name">h1</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">h1</span>&gt;</span>Hello ~<span class="hljs-tag">&lt;/<span class="hljs-name">h1</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br><br></code></pre></td></tr></table></figure></li><li><p>在浏览器中访问成功</p></li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/page1.png"></p><h1 id="三、安装Hexo"><a href="#三、安装Hexo" class="headerlink" title="三、安装Hexo"></a>三、安装Hexo</h1><ol><li><p>安装Hexo(cmd管理员模式下)和查看版本</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">npm install -g hexo-<span class="hljs-keyword">cli</span><br>hexo -v<br></code></pre></td></tr></table></figure><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/hexo_download.png"></p></li><li><p>创建一个项目并初始化</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo init hexo-blog<br><span class="hljs-built_in">cd</span> hexo-blog<br>npm install<br>//cmd管理员模式<br></code></pre></td></tr></table></figure><p>as</p></li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/hexo_init_1.png"></p><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/npm_install.png"></p><p>其内部文件结构如下（红框内为npm install 安装的）：</p><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/hexo-doc.png"></p><ol start="3"><li>本地启动<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs css">hexo <span class="hljs-selector-tag">g</span><br>hexo s<br></code></pre></td></tr></table></figure><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/hexo_start.png"></li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/hexo-doc-1.png"></p><p>如上所示，public文件夹内为新生成的web文件，共计11项。</p><ol start="4"><li>浏览器访问 <a href="http://localhost:4000/">http://localhost:4000</a></li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/web-1.png"></p><h1 id="四、更换主题"><a href="#四、更换主题" class="headerlink" title="四、更换主题"></a>四、更换主题</h1><h2 id="1、NexT主题"><a href="#1、NexT主题" class="headerlink" title="1、NexT主题"></a>1、NexT主题</h2><ol><li>下载NexT主题</li></ol><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs autoit">git clone git<span class="hljs-symbol">@github</span>.com:iissnan/hexo-theme-<span class="hljs-keyword">next</span>.git themes/<span class="hljs-keyword">next</span><br></code></pre></td></tr></table></figure><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/clone_next.png"></p><ol start="2"><li>打开 _config.yml 文件，该文件为站点配置文件</li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/theme_set_next.png"></p><ol start="3"><li>本地启动，出现以下显示问题</li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/next_error.png"></p><ol start="4"><li><p>原因是hexo在5.0之后把swig给删除了需要自己手动安装</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs coffeescript"><span class="hljs-built_in">npm</span> i hexo-renderer-swig<br></code></pre></td></tr></table></figure><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/npm_swig.png"></p></li><li><p>重新启动</p></li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/web-next.png"></p><p>参考：<a href="https://github.com/iissnan/hexo-theme-next/issues/2253">https://github.com/iissnan/hexo-theme-next/issues/2253</a></p><h2 id="2、Fluid主题"><a href="#2、Fluid主题" class="headerlink" title="2、Fluid主题"></a>2、Fluid主题</h2><ol><li>安装主题</li></ol><p>下载 <a href="https://github.com/fluid-dev/hexo-theme-fluid/releases">最新 release 版本</a> 解压到 <code>themes</code> 目录，并将解压出的文件夹重命名为 <code>fluid</code></p><ol start="2"><li>指定主题</li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/theme_set_fluid.png"></p><ol start="3"><li><p>创建[关于页]</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs actionscript">hexo <span class="hljs-keyword">new</span> page about<br></code></pre></td></tr></table></figure><p>编辑博客目录下 <code>/source/about/index.md</code>，添加 <code>layout</code> 属性。</p></li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/hexo_new_page_about.png"></p><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/page_about.png"></p><ol start="4"><li>重新启动</li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/web-fluid.png"></p><h1 id="五、创建文章"><a href="#五、创建文章" class="headerlink" title="五、创建文章"></a>五、创建文章</h1><h2 id="1、文章创建和图片插入"><a href="#1、文章创建和图片插入" class="headerlink" title="1、文章创建和图片插入"></a>1、文章创建和图片插入</h2><ol><li>修改 Hexo 博客目录中的 <code>_config.yml</code>，打开这个配置是为了在生成文章的时候生成一个同名的资源目录用于存放图片文件。</li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/config_set.png"></p><ol start="2"><li>创建一篇新文章，名为《测试文章》</li></ol><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">hexo <span class="hljs-built_in">new</span> <span class="hljs-built_in">post</span> 测试文章<br></code></pre></td></tr></table></figure><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/config_set_display.png"></p><ol start="3"><li>在md文件中插入图片的常用三种方式</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><br>&#123;<span class="hljs-string">%</span> <span class="hljs-string">asset_img</span> <span class="hljs-string">test.png</span> <span class="hljs-string">图片引用方法一</span> <span class="hljs-string">%</span>&#125;<br><br><br><span class="hljs-type">![</span><span class="hljs-string">图片引用方法二](test.png)</span><br><br><span class="hljs-string">需要在配置文件添加：</span><br><span class="hljs-attr">marked:</span><br>  <span class="hljs-attr">prependRoot:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">postAsset:</span> <span class="hljs-literal">true</span><br><br><br><br><span class="hljs-type">![</span><span class="hljs-string">图片引用方法三](/images/test.png)</span><br><span class="hljs-string">//images文件在在\source\images目录下</span><br><br></code></pre></td></tr></table></figure><p>如下分别是：</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs maxima">![](/测试文章/BA.jpg)<br>![](BA.jpg)<br>&#123;<span class="hljs-symbol">%</span> asset_img BA.jpg This <span class="hljs-built_in">is</span> an <span class="hljs-built_in">example</span> <span class="hljs-built_in">image</span> <span class="hljs-symbol">%</span>&#125;<br>&#123;<span class="hljs-symbol">%</span> asset_img <span class="hljs-string">&quot;BA.jpg&quot;</span> <span class="hljs-string">&quot;spaced title&quot;</span> <span class="hljs-symbol">%</span>&#125;<br></code></pre></td></tr></table></figure><p>对于如上四种中的第二种图片引用方法，需要对配置文件进行以下修改：</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-params">post_asset_folder:</span> <span class="hljs-literal">true</span><br><span class="hljs-params">marked:</span><br>  <span class="hljs-params">prependRoot:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-params">postAsset:</span> <span class="hljs-literal">true</span><br><br></code></pre></td></tr></table></figure><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/web-2-1.png"></p><h2 id="2、md文件图片同步显示"><a href="#2、md文件图片同步显示" class="headerlink" title="2、md文件图片同步显示"></a>2、md文件图片同步显示</h2><p>如果需要同时在md文件显示图片，需要安装<strong>hexo-asset-image</strong> 插件</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">npm install hexo-asset-<span class="hljs-selector-tag">image</span> <span class="hljs-attr">--save</span><br></code></pre></td></tr></table></figure><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/hexo_asset_image_dow.png"></p><p>重新启动</p><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/web-2-2.png"></p><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/web-2.png"></p><p>为什么会出现以下 &#x2F;.com&#x2F;&#x2F; 情况，其实是 <strong>hexo-asset-image</strong> 插件的bug</p><h3 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs verilog">npm uninstall hexo-asset-image<br>npm install https:<span class="hljs-comment">//github.com/CodeFalling/hexo-asset-image</span><br>hexo clean<br>hexo <span class="hljs-keyword">generate</span><br>hexo server <br></code></pre></td></tr></table></figure><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/hexo_asset_image_dow_1.png"></p><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/web-2-3.png"></p><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/web-2-3-1.png"></p><p>此时可以看出其他三种方法的解析路径出现多余的&#x2F;02&#x2F;10</p><h3 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h3><p>对hexo-asset-image（第一版）文件夹中的index.js中的文件进行如下修改：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-comment">//$(this).attr(&#x27;src&#x27;, config.root + link + src); </span><br>$(this)<span class="hljs-selector-class">.attr</span>(<span class="hljs-string">&#x27;src&#x27;</span>, data<span class="hljs-selector-class">.permalink</span><span class="hljs-selector-class">.split</span>(<span class="hljs-string">&#x27;example.com&#x27;</span>)<span class="hljs-selector-attr">[1]</span>+ <span class="hljs-attribute">src</span>);<br></code></pre></td></tr></table></figure><p>其问题如上图所示</p><p>参考：<a href="https://blog.csdn.net/sluck_0430/article/details/136431303">hexo图片显示不出且图片路径错误&#x2F;.com&#x2F;&#x2F;_hexo显示不了图片-CSDN博客</a></p><h3 id="方案三"><a href="#方案三" class="headerlink" title="方案三"></a>方案三</h3><p>对hexo-asset-image（第一版）文件夹中的index.js中的文件进行如下修改（第23行的else分支）：</p><figure class="highlight cal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cal">//<span class="hljs-keyword">var</span> endPos = link.lastIndexOf(<span class="hljs-string">&#x27;.&#x27;</span>);<br><span class="hljs-keyword">var</span> endPos = link.lastIndexOf(<span class="hljs-string">&#x27;/&#x27;</span>);<br></code></pre></td></tr></table></figure><p>其问题依然如上图所示</p><p>参考：<a href="https://blog.asroads.com/post/95d84581.html">Hexo生成博文插入图片 | Asroads’Blog</a></p><p>最终决定卸载hexo-asset-image插件</p><h1 id="六、个性化页面展示"><a href="#六、个性化页面展示" class="headerlink" title="六、个性化页面展示"></a>六、个性化页面展示</h1><h2 id="博客标题"><a href="#博客标题" class="headerlink" title="博客标题"></a>博客标题</h2><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-params">navbar:</span><br>  <span class="hljs-comment"># 导航栏左侧的标题，为空则按 hexo config 中 `title` 显示</span><br>  <span class="hljs-comment"># The title on the left side of the navigation bar. If empty, it is based on `title` in hexo config</span><br>  <span class="hljs-comment">#blog_title: &quot;Fluid&quot;</span><br>  <span class="hljs-params">blog_title:</span> <span class="hljs-string">&quot;blackstarry6&quot;</span><br></code></pre></td></tr></table></figure><h2 id="主页正中间的文字"><a href="#主页正中间的文字" class="headerlink" title="主页正中间的文字"></a>主页正中间的文字</h2><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nix"><span class="hljs-params">slogan:</span><br>  <span class="hljs-params">enable:</span> <span class="hljs-literal">true</span><br><br>  <span class="hljs-comment"># 为空则按 hexo config.subtitle 显示</span><br>  <span class="hljs-comment"># If empty, text based on `subtitle` in hexo config</span><br>  <span class="hljs-comment">#text: &quot;An elegant Material-Design theme for Hexo&quot;</span><br>  <span class="hljs-params">text:</span> <span class="hljs-string">&quot;XXX 个人博客&quot;</span><br></code></pre></td></tr></table></figure><h2 id="主页展示"><a href="#主页展示" class="headerlink" title="主页展示"></a>主页展示</h2><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/web-fluid-1.png"></p><h1 id="七、发布到Github-Pages"><a href="#七、发布到Github-Pages" class="headerlink" title="七、发布到Github Pages"></a>七、发布到Github Pages</h1><p>安装hexo-deployer-git</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs ada">npm install hexo-deployer-git <span class="hljs-comment">--save</span><br><br></code></pre></td></tr></table></figure><p>修改配置文件，其中 <code>token</code> 为 <code>GitHub</code> 的 <code>Personal access tokens</code></p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">deploy:</span><br><span class="hljs-symbol">  type:</span> git<br><span class="hljs-symbol">  repo:</span> XXX<br><span class="hljs-symbol">  branch:</span> main<br><span class="hljs-symbol">  token:</span> XXX<br><br></code></pre></td></tr></table></figure><p>部署到github</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">hexo <span class="hljs-selector-tag">g</span> -d<br></code></pre></td></tr></table></figure><p>参考：</p><p><a href="https://blog.csdn.net/yaorongke/article/details/119089190">GitHub Pages + Hexo搭建个人博客网站，史上最全教程_hexo博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/yaorongke/article/details/119085413">Git安装(Windows)_windows git安装包-CSDN博客</a></p><p><a href="https://blog.csdn.net/yaorongke/article/details/119084295">NodeJS安装及配置(Windows)_welcome to node.js v14.21.3. type “.help” for more-CSDN博客</a></p><p><a href="https://blog.csdn.net/zimeng303/article/details/112167688">NodeJs 的安装及配置环境变量_nodejs配置环境变量-CSDN博客</a></p><p><a href="https://blog.csdn.net/m0_43401436/article/details/107191688">hexo博客中插入图片失败——解决思路及个人最终解决办法_hexo 文章插入图片失败-CSDN博客</a></p><h1 id="附录：SSH配置"><a href="#附录：SSH配置" class="headerlink" title="附录：SSH配置"></a>附录：SSH配置</h1><ol><li>生成密钥对</li></ol><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">ssh</span>-keygen -t ed25519 -C <span class="hljs-string">&quot;your_email@example.com&quot;</span><br><br><span class="hljs-comment">//如果您使用的是不支持 Ed25519 算法的旧版系统，请使用</span><br><span class="hljs-symbol">ssh</span>-keygen -t rsa -<span class="hljs-keyword">b</span> <span class="hljs-number">4096</span> -C <span class="hljs-string">&quot;your_email@example.com&quot;</span><br></code></pre></td></tr></table></figure><ol start="2"><li><p>在.&#x2F;ssh文件下查看生成的密钥对，复制.pub内的公钥内容</p></li><li><p>Github账号上添加公钥</p></li></ol><p><code>Settings</code>&#x3D;&gt;<code>SSH and GPG keys</code>&#x3D;&gt;<code>New SSH key</code>&#x3D;&gt;<code>Key</code>，在title中简单描述一下</p><ol start="4"><li>验证是否成功，即连接github服务器，此时出现如下情况：</li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/ssh-1.png"></p><ol start="5"><li>换成443端口：</li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/ssh-2.png"></p><ol start="6"><li>对.&#x2F;ssh文件中的config文件（没有的话自己建立）进行如下修改：</li></ol><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># Add section below to it</span><br><span class="hljs-attribute">Host</span> github.com<br>  <span class="hljs-attribute">Hostname</span> ssh.github.com<br>  <span class="hljs-attribute">Port</span> <span class="hljs-number">443</span><br><br></code></pre></td></tr></table></figure><ol start="7"><li>重新连接github服务器：</li></ol><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/ssh-3.png"></p><p>参考链接：</p><p><a href="https://blog.csdn.net/weixin_42310154/article/details/118340458">Github配置ssh key的步骤（大白话+包含原理解释）_github生成ssh key-CSDN博客</a></p><p><a href="https://githubdocs.cn/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent?platform=windows">在 SSH 代理中生成新的 SSH 密钥并添加它 - GitHub 文档 - GitHub 文档</a></p><p><a href="https://blog.csdn.net/misakivv/article/details/144929627">解决 ssh connect to host github.com port 22 Connection timed out_ssh: connect to host gitlab.sdlg.cn port 30022: co-CSDN博客</a></p><h2 id="可能出现的问题和解决方案"><a href="#可能出现的问题和解决方案" class="headerlink" title="可能出现的问题和解决方案"></a>可能出现的问题和解决方案</h2><p><img src="/2025/02/19/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%B5%81%E7%A8%8B/git_solve_1.png"></p><p>来源：<a href="https://blog.csdn.net/fearlessxmm/article/details/90401690">https://blog.csdn.net/fearlessxmm/article/details/90401690</a>  </p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>Web</category>
      
    </categories>
    
    
    <tags>
      
      <tag>web</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>测试文章</title>
    <link href="/2025/02/10/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/"/>
    <url>/2025/02/10/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p>1</p><p><img src="/2025/02/10/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/BA.jpg"></p><p>1</p><p>banner_img:&#x2F;测试文章&#x2F;BA.jpg</p><p>官方引用</p><img src="/2025/02/10/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/BA.jpg" class="" title="This is an example image"><img src="/2025/02/10/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/BA.jpg" class="" title="spaced title">]]></content>
    
    
    
    <tags>
      
      <tag>exam</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2025/02/10/hello-world/"/>
    <url>/2025/02/10/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>exam</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
